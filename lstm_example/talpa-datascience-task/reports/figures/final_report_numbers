state_labels = ["Anchoring: 0", "Drilling:1", "Hole Setup:2", "Idle:3", "Machine Off:4", "Translational Delay:5", "Travelling"]
# The Precision, recall and fscore for each class label is

precision: [0., 0.9734589,  0.87209302, 0.96542553, 0.99522546, 0.95524691, 0.96940195]
recall: [0., 0.98869565, 0.84269663, 0.94285714, 0.99946723, 0.91703704, 0.96403873]
fscore: [0., 0.98101812, 0.85714286, 0.95400788, 0.99734184, 0.93575208, 0.9667129 ]

a=[[[4990,    0],
  [   2,    0]]

 [[3808,   26],
  [17, 1141]]

 [[4782,   28],
  [  16,  166]]

 [[4546   20]
  [  20  406]]

 [[3066    7]
  [   9 1910]]

 [[4333   20]
  [  44  595]]

 [[4313   13]
  [  31  635]]]

  Example of a confusion matrix
  [[   0    1    0    0    0    3    0]
 [   2 1137    4    0    0    7    0]
 [   6    4  150    0    0   16    2]
 [   1    0    0  363    1    1   19]
 [   1    0    0    0 1876    0    0]
 [  10   26   15    0    4  619    1]
 [   4    0    3   13    4    2  697]]

Classification report for all classes:
            precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.97      0.99      0.98      1150
           2       0.87      0.84      0.86       178
           3       0.97      0.94      0.95       385
           4       1.00      1.00      1.00      1877
           5       0.96      0.92      0.94       675
           6       0.97      0.96      0.97       723

   micro avg       0.97      0.97      0.97      4992
   macro avg       0.82      0.81      0.81      4992
weighted avg       0.97      0.97      0.97      4992
 samples avg       0.97      0.97      0.97      4992
